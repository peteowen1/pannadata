name: Daily Opta Scrape

on:
  schedule:
    # Run at 5 AM UTC daily (before Understat at 7 AM)
    - cron: '0 5 * * *'
  workflow_dispatch:
    inputs:
      leagues:
        description: 'Leagues to scrape (space-separated, e.g., "EPL La_Liga")'
        required: false
        type: string
      recent:
        description: 'Number of recent seasons to scrape per league'
        required: false
        type: number
        default: 1
      force_rescrape:
        description: 'Force rescrape existing matches'
        required: false
        type: boolean
        default: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 360

    permissions:
      contents: write

    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    steps:
    - name: Checkout pannadata
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: scripts/opta/requirements.txt

    - name: Install Python dependencies
      run: pip install -r scripts/opta/requirements.txt

    - name: Download manifest from GitHub Releases
      run: |
        mkdir -p data
        echo "Downloading manifest..."
        if gh release download opta-latest --pattern "opta-manifest.parquet" --dir data/ 2>/dev/null; then
          echo "Downloaded opta-manifest.parquet"
          echo "Manifest size: $(ls -lh data/opta-manifest.parquet | awk '{print $5}')"
        else
          echo "No manifest found (first run or new setup)"
        fi
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Download existing per-league parquet files
      run: |
        mkdir -p data/opta/player_stats data/opta/shots data/opta/match_events data/opta/lineups data/opta/events data/opta/shot_events data/opta/fixtures
        echo "Downloading existing consolidated files..."

        # Download consolidated files (player_stats, shots, etc.)
        for file in opta_player_stats.parquet opta_shots.parquet opta_shot_events.parquet opta_events.parquet opta_lineups.parquet opta_fixtures.parquet; do
          if gh release download opta-latest --pattern "$file" --dir data/ 2>/dev/null; then
            echo "Downloaded $file"
          fi
        done

        # Download per-league events files
        mkdir -p data/consolidated/match_events
        for file in $(gh release view opta-latest --json assets -q '.assets[].name' 2>/dev/null | grep "^events_" || true); do
          if gh release download opta-latest --pattern "$file" --dir data/consolidated/match_events/ 2>/dev/null; then
            echo "Downloaded $file"
          fi
        done

        echo "Download complete"
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Run Opta scraper
      run: |
        cd scripts/opta
        ARGS="--recent ${{ github.event.inputs.recent || 1 }}"
        if [ -n "${{ github.event.inputs.leagues }}" ]; then
          ARGS="$ARGS --leagues ${{ github.event.inputs.leagues }}"
        fi
        if [ "${{ github.event.inputs.force_rescrape }}" = "true" ]; then
          ARGS="$ARGS --force"
        fi
        echo "Running: python scrape_opta.py $ARGS"
        python scrape_opta.py $ARGS

    - name: Build consolidated parquet files
      run: |
        cd data
        PARQUET_COUNT=$(find opta -name "*.parquet" 2>/dev/null | wc -l)
        echo "Total parquet files: $PARQUET_COUNT"
        if [ "$PARQUET_COUNT" -eq 0 ]; then
          echo "No parquet files to consolidate"
          exit 0
        fi
        mkdir -p consolidated
        python ../scripts/opta/consolidate_opta.py

    - name: Upload to GitHub Releases
      run: |
        cd data

        # Ensure release exists
        if ! gh release view opta-latest >/dev/null 2>&1; then
          gh release create opta-latest --title "Opta Data (Latest)" --notes "Automated daily Opta data scrape. Uses manifest-based incremental updates." --prerelease
        fi

        # Upload manifest (critical for incremental scraping)
        if [ -f "opta-manifest.parquet" ]; then
          gh release upload opta-latest opta-manifest.parquet --clobber
          echo "Uploaded opta-manifest.parquet ($(ls -lh opta-manifest.parquet | awk '{print $5}'))"
        fi

        # Upload consolidated parquets (by table type)
        for f in consolidated/opta_*.parquet; do
          [ -f "$f" ] && gh release upload opta-latest "$f" --clobber && echo "Uploaded $(basename $f)"
        done

        # Upload per-league events files
        if [ -d "consolidated/match_events" ]; then
          for f in consolidated/match_events/events_*.parquet; do
            [ -f "$f" ] && gh release upload opta-latest "$f" --clobber && echo "Uploaded $(basename $f)"
          done
          echo "Uploaded $(ls consolidated/match_events/events_*.parquet 2>/dev/null | wc -l) events files"
        fi

        echo "Upload complete"
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Summary
      run: |
        echo "Daily Opta scrape completed"
        echo "Manifest: $(ls -lh data/opta-manifest.parquet 2>/dev/null | awk '{print $5}' || echo 'Not found')"
        echo "Raw parquet files: $(find data/opta -name '*.parquet' 2>/dev/null | wc -l)"
        echo "Consolidated by table:"
        ls -lh data/consolidated/opta_*.parquet 2>/dev/null || echo "  None"
        echo "Events by league: $(ls data/consolidated/match_events/events_*.parquet 2>/dev/null | wc -l) files"
